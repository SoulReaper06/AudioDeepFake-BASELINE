{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, max_time_steps=109, sample_rate=22050, duration=3, n_mels=128):\n",
    "    audio, _ = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your file paths and constants\n",
    "TRAINING_LABEL = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "TRAINING_DATA = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac'\n",
    "VALIDATION_DATA = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac'\n",
    "VALIDATION_LABEL = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "SAMPLE_RATE = 22050  # Adjust if your sample rate is different\n",
    "DURATION = 3  # Adjust the duration of your audio samples\n",
    "N_MELS = 128  # Adjust the number of mel filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for training Data\n",
    "train_labels = {}\n",
    "\n",
    "with open(TRAINING_LABEL, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    train_labels[file_name] = label\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in train_labels.items():\n",
    "    file_path = os.path.join(TRAINING_DATA, file_name + \".flac\")\n",
    "\n",
    "    # Use the preprocess_data function\n",
    "    mel_spectrogram = preprocess_data(file_path, max_time_steps=max_time_steps)\n",
    "\n",
    "    X.append(mel_spectrogram)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape input data to match the required input shape for ResNet\n",
    "X = X.reshape((X.shape[0], X.shape[1], X.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape and number of classes\n",
    "input_shape = X[0].shape\n",
    "num_classes = 2  # Assuming you have two classes (0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess evaluation data\n",
    "eval_X = []\n",
    "eval_y = []\n",
    "\n",
    "with open(VALIDATION_LABEL, 'r') as eval_label_file:\n",
    "    eval_lines = eval_label_file.readlines()\n",
    "\n",
    "eval_labels = {}\n",
    "\n",
    "for line in eval_lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    eval_labels[file_name] = label\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in eval_labels.items():\n",
    "    file_path = os.path.join(VALIDATION_DATA, file_name + \".flac\")\n",
    "\n",
    "    # Use the preprocess_data function\n",
    "    mel_spectrogram = preprocess_data(file_path, max_time_steps=max_time_steps)\n",
    "\n",
    "    eval_X.append(mel_spectrogram)\n",
    "    eval_y.append(label)\n",
    "\n",
    "eval_X = np.array(eval_X)\n",
    "eval_y = np.array(eval_y)\n",
    "\n",
    "\n",
    "# Reshape input data to match the required input shape for ResNet\n",
    "eval_X = eval_X.reshape((eval_X.shape[0], eval_X.shape[1], eval_X.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet block\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False):\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Build the ResNet model\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # ResNet blocks\n",
    "    for size in [64, 128, 256, 512]:\n",
    "        x = resnet_block(x, size, conv_shortcut=True)\n",
    "        x = resnet_block(x, size)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ResNet model\n",
    "resnet_model = build_resnet(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model summary\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "epochs = 50  # Adjust the number of epochs as needed\n",
    "\n",
    "history = resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(eval_X, eval_y))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = history.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Evaluate the model on the separate evaluation dataset\n",
    "eval_loss, eval_accuracy = history.evaluate(eval_X, eval_y)\n",
    "print(f'Evaluation Loss: {eval_loss:.4f}, Evaluation Accuracy: {eval_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = resnet_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Evaluate the model on the separate evaluation dataset\n",
    "eval_loss, eval_accuracy = resnet_model.evaluate(eval_X, eval_y)\n",
    "print(f'Evaluation Loss: {eval_loss:.4f}, Evaluation Accuracy: {eval_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "resnet_model.save(\"models/basic_resnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Make Predictions\n",
    "def makePrediction(audio_file_path, model_file, max_time_steps):\n",
    "    mel_spectrogram = preprocess_data(audio_file_path, max_time_steps=max_time_steps)\n",
    "\n",
    "    #reshaping the spectrogram \n",
    "    input_data = np.expand_dims(mel_spectrogram, axis=0)\n",
    "\n",
    "    print(input_data.shape)\n",
    "\n",
    "    result = ''\n",
    "    threshold = 0.377089\n",
    "\n",
    "    # Predict using the loaded classifier\n",
    "    prediction = model_file.predict(input_data)\n",
    "\n",
    "    # Convert the prediction to a human-readable label\n",
    "    if (prediction[0][1] > threshold):\n",
    "        result = \"BONAFIDE\"\n",
    "    else:\n",
    "        result = \"SPOOF\"    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 109)\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "SPOOF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "max_time_steps = 109\n",
    "\n",
    "audio_file1 = \"/home/jonat/test2.wav\"\n",
    "audio_file2 = \"/home/jonat/MAIN-PROJECT/test-audios/5sec-audio.wav\"\n",
    "audio_file3 = \"/home/jonat/MAIN-PROJECT/test-audios/tts-robot.wav\"\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = tf.keras.models.load_model('/home/jonat/AudioDeepFake_Baseline_Test/models/basic_resnet.h5')\n",
    "\n",
    "prediction_result = makePrediction(audio_file3,model_file=model,max_time_steps=109)\n",
    "\n",
    "print(prediction_result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NESL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
